\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2019

% ready for submission
%\usepackage{neurips_2019_ml4ad}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
 \usepackage[preprint, nonatbib]{neurips_2019_ml4ad}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{neurips_2019_ml4ad}

% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{neurips_2019_ml4ad}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

% Custom packages
\usepackage[round]{natbib}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{float}
\usetikzlibrary{arrows,automata}
\usepackage{pgfplots}
\usetikzlibrary{intersections}
\usepackage{subcaption}
\usepackage[flushleft]{threeparttable}
\usepackage{cases}

\input{mathdef}

\title{Social Attention for Autonomous Decision-Making in Dense Traffic}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

%Happy Horizontal People Transporter
%From the Sirius Cybernetics Corporation with a Genuine People Personality

\author{%
  Edouard Leurent\thanks{Equal contribution.} \\
  SequeL team, INRIA Lille -- Nord Europe\\
  Renault Group, France\\
  \texttt{edouard.leurent@inria.fr} \\
  % examples of more authors
   \And
  Jean Mercat$^*$ \\
  Laboratoire des signaux et des syst\`emes, Centrale-Sup\'elec\\
  Renault Group, France\\
  \texttt{jean.mercat@renault.com} \\
}

\begin{document}
	
	
	\tikzset{
		state/.style={
			rectangle,
			draw=black, very thick,
			minimum height=2em,
			inner sep=2pt,
			text centered,
		},
		name plot/.style={every path/.style={name path global=#1}}
	}
	
	\pgfmathdeclarefunction{dnorm}{2}{%
		\pgfmathparse{1/(#2*sqrt(2*pi))*exp(-((x-#1)^2)/(2*#2^2))}%
	}
	

\maketitle

\begin{abstract}
  The abstract paragraph should be indented \nicefrac{1}{2}~inch (3~picas) on
  both the left- and right-hand margins. Use 10~point type, with a vertical
  spacing (leading) of 11~points.  The word \textbf{Abstract} must be centered,
  bold, and in point size 12. Two line spaces precede the abstract. The abstract
  must be limited to one paragraph.
\end{abstract}

\section{Introduction}

In the last decades, the problem of \emph{behavioural planning} -- that is, high-level decision-making in the context of autonomous driving -- has arguably received less attention and seen less progress than the other components of the typical robotics pipeline: perception and control \citep{architecture}. Indeed, the vast majority of existing systems still rely on hand-crafted rules encoded as Finite State Machines \citep{fsm}. As a result, only a narrow set of specified use-cases are addressed as these methods cannot scale to more complex scenes, especially when the decision-making process involves interacting with other human drivers whose behaviour is uncertain and difficult to model explicitly.

This observation has led the community to turn to learning-based methods, which bear the promise of leveraging data to automatically learn a complex driving policy. In the \emph{imitation learning} approach, a policy can be trained in a supervised setting to imitate human driving decisions \citep{supervised, waymo}. Because the cost of human driving data collection at large scale can be prohibitive, another promising approach is train a policy in simulation using reinforcement learning \citep{examples}.

Beyond the choice of reinforcement learning algorithm, the formalization of the problem as a \emph{Markov Decision Process} (MDP) plays an important part in the design of the system. In particular, the choice of state and action spaces can have a significant influence on the performance of resulting policy. Describing a driving scene typically involves choosing a representation the road, signalization, and vehicles. The simplest form: a list of vehicles with their coordinates, orientations, velocities. But variable size and order dependent. Another common format is a spatial matrix, either cartesian (images, occupancy grid) or polar (distances in angular sectors). Fixed size and order independent, but accuracy/size tradeoff. Challenge: keep a small state size, but enforce that the model is invariant to permutations.

Contributions:
- We propose an attention-based architecture for decision-making involving social interactions, that accounts for two-way interactions between the ego-vehicle and every other traffic participant
- We evaluate our model on a challenging intersection-crossing task involving up to 20 vehicles perceived simultaneously.

\section{Background and Related Work}

\paragraph{Model-free deep reinforcement learning} Reinforcement Learning is a general framework for sequential decision-making under uncertainty. It frames the learning objective as the optimal control of a Markov Decision Process $(S, A, P, R, \gamma)$ with measurable state space $S$, action space $A$, unknown reward function $R\in\Real^{S \times A}$, and unknown dynamics $P\in \cM(S)^{S \times A}$, where $\cM(\mathcal{X})$ denotes the probability measures over a set $\mathcal{X}$. The objective is to find a policy $\pi\in\cM(A)^S$ with maximal expected $\gamma$-discounted cumulative reward, called the value function $V^\pi$. Formally,

\begin{align*}
V^\pi(s) &\eqdef \expectedvalue\left[\sum_{t=0}^\infty \gamma^t R(s_t, a_t)\condbar s_0=s, a_t\sim \pi(a_t|s_t), s_{t+1}\sim P(s_{t+1}|s_t, a_t)\right]\\
Q^\pi(s, a) &\eqdef R(s, a) + \gamma \expectedvalueover{s'\sim P(s'|s, a)} V^\pi(s')
\end{align*}

The optimal action-value function $Q^* =  \max_\pi Q^\pi(s)$ satisfies the Bellman Optimality Equation \citep{bellman}:
\begin{equation*}
Q^*(s, a) = (\cT Q^*) (s, a) \eqdef \expectedvalueover{s'\sim P(s'|s, a)} \max_{a'\in A} \left[R(s, a) + \gamma Q^*(s', a')\right]
\end{equation*}

As $Q^*$ is a fixed-point of the Bellman Operator $\cT$ -- which is a contraction --, it can be computed by applying $\cT$ iteratively in a fixed-point iteration fashion. The \emph{Q-learning} algorithm \citep{Watkins} follows this procedure by applying a sampling version $\cT$ to a batch of collected experience. When dealing with a continuous state space $S$, we need to employ function approximation in order to generalise to nearby states. The \emph{Deep Q-Network} (DQN) algorithm \citep{Mnih} implements this idea by using a neural network model to represent the action-value function $Q$.

\paragraph{State-representation for social interactions}{

A vehicle driving on a road can be described in the most general way by it's continuous position, heading and velocity. The composite state (or joint-state) of a road traffic with one ego-vehicle (denoted $X_0$) and N other vehicles can then be described by the set of the states of all vehicles.

\begin{equation*}
s = \left\lbrace s_k \right\rbrace_{k \in [0, N]}\qquad
,\text{where}\qquad
s_k = \begin{bmatrix}
x_k & y_k & v^x_k & v^y_k & \cos\psi_k & \sin \psi_k
\end{bmatrix}^T
\end{equation*}


\begin{figure}[tp]
	\centering
	\includegraphics[width=0.25\textwidth]{img/coordinates}
	\includegraphics[width=0.25\textwidth]{img/map}
	\caption{The continuous kinematics, and spatial grid representations}
\end{figure}

The size of this state-space is $\mathbb{R}^{6(N+1)}$.

This representation is used in \citep{Forbes1995, Wheeler2015, Bai2015, Gindele2015, Song2016, Sunberg2017, Paxton2017, Lee2017, Shalev-Shwartz2017, Galceran2017, Chen2017, Paxton2017}.


This encoding is efficient in the sense that it uses the smallest quantity of information necessary to represent the scene. However, it lacks two important properties. First, its size varies with the number of vehicles, which can be problematic for the sake of function approximation which often expects constant-sized inputs but also to because of the growing computational complexity when more vehicles are present. Second, we expect a driving policy to be \emph{permutation invariant}, i.e. not to be dependent on the order in which all vehicles in the traffic are listed. Ideally, this property should be enforced instead of relying on data augmentation to cover the $N!$ possible permutations of any given traffic state. Formally, we require that 
\begin{equation}
\pi(\cdot|(s_1,\dotsc,s_N)) = \pi(\cdot|(s_{\sigma(1)},\dotsc,s_{\sigma(N)})) \quad\quad\quad \forall\sigma \in \mathfrak{S}_N
\end{equation}

These limitations are addressed by the spatial matrix representation, that uses a different approach for representing a quantity $z$ localized in a space $X$. Instead of explicitly representing spatial dimensions as variables $x$ within a state $\{s_k=(x_k,z_k)\}_{k\in[0,N]}$ indexed on the vehicles, they are represented implicitly through the layout of several variables $z_i$ organized in a grid-like structure indexed on a quantization of the space $X$.

\begin{equation}
X = \underset{i\in I}{\oplus} X_i
\end{equation}

\begin{equation}
s_{i} = \begin{cases}
z_k & if \exists k\in[1,N] s.t. x_k \in X_i \\
0 & else
\end{cases}
\end{equation}

The $z$ variable often corresponds to mere presence information (0-1) but can also include additional channels such as heading and velocity.
The size of this state space is then $|Z|^{|I|}$.
This representation is used in \citep{Mukadam2018, Isele2017, Fridman2018}.

TODO: Can also include other layers, and top-view images
State dimensionality is |I| = product(Size / Accuracy)

Transition:
This permutation invariance property can be implemented within the policy architecture, as done in \citep{Chen2017} or \citep{Qi2016}, but also directly in the state representation.
Weight sharing and reduce operator that is \citep{Socially aware, point_net}.
A particular instantiation of this idea: attention.


\paragraph{Attention mechanisms} {in neural networks have been able to introduce inter-dependencies within a variable number of inputs.
It has been used for pedestrian trajectory forecasting in~\cite{Vemula2018} with spatiotemporal graphs and
in~\cite{Sadeghian2019CVPR} with spatial and social attention using a generative neural network.
In~\cite{Sadeghian2018ECCV}, attention over top-view road scene images for car trajectory forecasting is used.
Multi-head attention mechanism has been developed in~\cite{Vaswani2017} for sentence translation.
In~\cite{Messaoud2019} a mechanism called non-local multi-head attention is developed.
However, this is a spatial attention that does not allow vehicle-to-vehicle attention.

In the present work, we use a multi-head social attention mechanism working together with
recurrent neural networks to forecast in the form of sequences of multi-modal position probability density
functions.}

\section{Model Architecture}

Motivation: 
\begin{enumerate}
	\item Out of a complex scene description, the model should be able to filter information and consider only what is relevant for decision. In other words, the agent should \emph{pay attention} to vehicles that are close or conflict with the planned route;
	\item The model should be able to admit a variable number of vehicles as inputs;
	\item The model should be invariant to the ordering of vehicles.
\end{enumerate}


\begin{figure}[ht]
	\centering
	\begin{tikzpicture}
	\node(X1){ego};
	\node[below of=X1, node distance=0.7cm](X2){vehicle$_{1}$};
	\node[below of=X2, node distance=0.6cm](X3){$\vdots$};
	\node[below of=X3, node distance=0.7cm](X4){vehicle$_{n}$};
	
	\node[draw, right of=X1, node distance=1.8cm, rectangle](ENC1){Encoder};
	\node[draw, right of=X2, node distance=1.8cm, rectangle](ENC2){Encoder};
	\node[below of=ENC2, node distance=0.6cm](ENC3){$\vdots$};
	\node[draw, right of=X4, node distance=1.8cm, rectangle](ENC4){Encoder};
	
	\path (X1) edge (ENC1);
	\path (X2) edge (ENC2);
	\path (X4) edge (ENC4);
	
	
	\node[draw, rectangle, right of=ENC1, node distance=1.8cm, below=-0.2cm](TRANS1){\rotatebox{90}{ Ego-attention }};
	
	\draw (ENC1.east) -| (TRANS1.west);
	\draw (ENC2.east) -| (TRANS1.west);
	\draw (ENC4.east) -| (TRANS1.west);
	
	
	\node[draw, right of=ENC1, node distance=3.6cm, rectangle](DEC1){Decoder};
	
	\draw (TRANS1.east) |- (DEC1.west);

	\node[right of=DEC1, node distance=2.3cm](Y1){action values};
	
	\draw (DEC1.east) -- (Y1.west);
	\end{tikzpicture}
	\caption{Block diagram of our model architecture.}
	\label{sch_whole_model}
	
\end{figure}


The multi-head self-attention layers allow vehicle interactions while keeping independence from their number
and ordering.
This mechanism is described in~\cite{Vaswani2017} where it is applied on sentence translation.
In this section we explain its use for vehicle interactions.
The computations made by each attention head is represented on figure~\ref{fig:ego-attention} and are detailed below.

\begin{figure}[ht]
	\centering
	\begin{tikzpicture}[scale=1, every node/.style={scale=1}]
	\node(X1){ego encoding};
	\node[below of=X1, node distance=2cm](X2){$\vdots$};
	\node[below of=X2, node distance=2cm](X3){vehicle$_{n}$ encoding};
	
	\coordinate[right of= X1, node distance=2cm](X1b){};
	
	\draw (X1) -- (X1b);
	
	\node[draw, right of=X1b, node distance=1cm](LK1){$L_{k}$};
	\node[draw, below of=LK1, node distance=1cm](LV1){$L_{v}$};
	\node[draw, above of=LK1, node distance=1cm](LQ1){$L_{q}$};
	
	\draw (X1b) -- (LQ1);
	\draw (X1b) -- (LK1);
	\draw (X1b) -- (LV1);
	

	\node[right of=LQ1, node distance=1cm](Q1){$\mathbf{q}_0$};
	\node[right of=LK1, node distance=1cm](K1){$\mathbf{k}_0$};
	\node[right of=LV1, node distance=1cm](V1){$\mathbf{v}_0$};
	
	\draw (LQ1) -- (Q1);
	\draw (LK1) -- (K1);
	\draw (LV1) -- (V1);
	
	\coordinate[right of= X3, node distance=2cm](X3b){};
	
	\draw (X3) -- (X3b);
	
	\node[draw, right of=X3b, node distance=1cm](LK3){$L_{k}$};
	\node[draw, below of=LK3, node distance=1cm](LV3){$L_{v}$};

	\draw (X3b) -- (LK3);	
	\draw (X3b) -- (LV3);
	
	\node[right of=LK3, node distance=1cm](K3){$\mathbf{k}_{n}$};
	\node[right of=LV3, node distance=1cm](V3){$\mathbf{v}_{n}$};

	\draw (LK3) -- (K3);
	\draw (LV3) -- (V3);
	
	\coordinate[right of=Q1, node distance=0.3cm](TOP){};
	\coordinate[right of=V3, node distance=0.3cm](BOT){};
	\draw[decorate,decoration={brace}] (TOP) -- node[left=5pt]{} (BOT);
	
	\node[right of=X2, text width=3cm, node distance=5.5cm](EQ){
		\footnotesize \[Q = \left( \begin{matrix}
		\mathbf{q}_0
		\end{matrix} \right)\]
		\\
		\footnotesize \[K = \left( \begin{matrix}
		\mathbf{k}_0 \\
		\vdots \\
		\mathbf{k}_{n}
		\end{matrix} \right)\]
		\\
		\footnotesize \[ V = \left( \begin{matrix}
		\mathbf{v}_0 \\
		\vdots \\
		\mathbf{v}_{n}
		\end{matrix}\right) \]
	};

	\node[draw, right of=X2, node distance=8.3cm](EQ2){
	\footnotesize $\sigma\left(\frac{QK^T}{\sqrt{d_k}}\right)V$};

	\coordinate[left of=EQ2, node distance=1.6cm, above=2.2cm](TOP2){};
	\coordinate[left of=EQ2, node distance=1.5cm, below=0.0cm](MID2){};
	\coordinate[left of=EQ2, node distance=1.6cm, below=2.2cm](BOT2){};
	\draw[decorate,decoration={brace}] (TOP2) -- node[left=5pt]{} (BOT2);
	\draw (MID2) -- (EQ2);
	
	\node[right of=EQ2, node distance=2cm](OUT){output};
	\draw (EQ2) -- (OUT);
	
	\end{tikzpicture}
	\caption{Architecture of an ego-attention head.
		The blocks $L_{q}$, $L_{k}$, $L_{v}$ are linear layers. The keys $K$ and values $V$ are concatenated from all vehicles, while the query $Q$ is only produced by the ego-vehicle.}
	\label{fig:ego-attention}
\end{figure}

Each vehicle should pay attention to specific features from a selection of the other vehicles.
This is made with four steps: pulling together specific features, identifying these feature collections,
enquiring among identifiers, and gathering the results.
Each head produces a different selection of features using a linear projection of
the input tensor resulting in the value tensor $V$.
To identify these features, a key tensor $K$ is associated to each value.
Then, each vehicle must select which other vehicle to pay attention to.
For that purpose a query $Q$ is produced to find a selection of keys.
The match score between a key and a query is the dot product is scaled with the square root of the key
dimension $\sqrt{d_k}$ and normalized with a softmax.
This produces an attention matrix that contains coefficients close to $1$ for matching queries and keys
and close to $0$ otherwise.
Finally, this matrix is used to gather the values from $V$.
Thus, the self-attention computation for each head is written:
\begin{equation}
\text{output}=\underbrace{\sigma\left(\frac{QK^T}{\sqrt{d_k}}\right)}_{\text{attention matrix}}V
\label{eq_selfattention}
\end{equation}
The outputs from all heads are concatenated and combined with a linear layer.
The resulting tensor is then added to the input as in residual networks.


\section{Experiments}
\subsection{Description of the environment}

In this application, we use the \href{https://github.com/eleurent/highway-env}{highway-env} environment \citep{highway-env} for simulated highway driving and behavioural decision-making. We propose a new task where vehicles must interact significantly with each others: a four-way intersection. The scene, composed of two roads crossing perpendicularly, is populated with several traffic participants initialized with random positions, velocities, and destinations. As in \citep{highway-env}, these vehicle are simulated with the Kinematic Bicycle Model, their lateral control is achieved by a low-level steering controller and their longitudinal behaviour follows the Intelligent Driver Model. However, this model only considers same-lane interactions and special care was required to prevent the lateral collisions at the intersection. To that end, we implemented the following simplistic behaviour: each vehicle predicts the future positions of its neighbours over a three-second horizon by using a constant velocity model. In case of predicted collision with a neighbour, the yielding vehicle is determined randomly and must brake until the collision prediction ceases. 

In this context, the agent must drive a vehicle by controlling its acceleration chosen from a finite set of actions $A = \{\texttt{SLOWER}, \texttt{NO-OP}, \texttt{FASTER}\}$. The lateral control is performed automatically by a low-level controller, such that the problem complexity is focused on the high-level interactions with other vehicles, namely the decision to either yield or take way. The agent is rewarded by $1$ when it drives at maximum velocity, $0$ otherwise, and by $-5$ when a collision occurs.

\subsection{Agents}

\subsection{Results}


\begin{table}
	\centering
	\begin{threeparttable}
    \caption{Results}
	\begin{tabular}{lcc}
		\toprule
		Architecture & MLP & Ego-Attention \\
		\midrule 
		Layers sizes & [128, 128] & [64, 64], 64, [64, 64] \\
		Number of parameters & \textbf{3.0e4} & 3.4e4 \\
		Inference Time$^*$ & \textbf{1} & 1.25 \\
		Mean total reward & 3.6 & \textbf{6.4} \\ 
		\bottomrule
	\end{tabular}
	\begin{tablenotes}
		\small
		\item $^*$ with respect to MLP.
	\end{tablenotes}
	\end{threeparttable}
\end{table}

\begin{figure}
	\centering
	\begin{subfigure}[t]{.65\linewidth}
		\centering\includegraphics[width=\linewidth]{img/total_rewards}
		\caption{Cumulative reward}
	\end{subfigure}
\\
	\begin{subfigure}[t]{.65\linewidth}
		\centering\includegraphics[width=\linewidth]{img/total_length}
		\caption{Episode length}
	\end{subfigure}
\\
	\begin{subfigure}[t]{.65\linewidth}
		\centering\includegraphics[width=\linewidth]{img/collision}
		\caption{Probability of collision}
	\end{subfigure}
\end{figure}

\subsection{Attention interpretation}

Additional videos are available at \url{http://url.github.io}

\section{Conclusion}

\subsubsection*{Acknowledgments}

Use unnumbered third level headings for the acknowledgments. All acknowledgments
Go at the end of the paper. Do not include acknowledgments in the anonymized
submission, only in the final paper.

\section*{References}

\bibliographystyle{named}
\bibliography{references}




\end{document}
